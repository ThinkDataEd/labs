---
title: "What's the score?"
author: "Lab 4B"
date: 'Directions: Follow along with the slides, completing the questions in <font color=#25679E><b>blue</b></font> on your computer, and answering the questions in **red** in your journal.  
  
  <br>
  <br>
  Space, Click, Right Arrow or swipe left to move to the next slide.'
output: 
  slidy_presentation: 
    css: ../../IDSLabCSSRev.css
    mathjax: ../../extras/mathjax-local/MathJax.js
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, eval=TRUE, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
library(mobilizr)
```

## Previously

- In the previous lab, we learned we could make predictions about one variable by utilizing the information of another.
- In this lab, we will learn how to measure the accuracy of our predictions.
    - This in turn will let us evaluate how well a model performs at making predictions.
    - We'll also use this information later to compare different models to find which model makes the best predictions.


## Predictions using a line

- <span class="blue">Load the `arm_span` data again.</span>
- **(1) Write and run code creating an `xyplot` with `height` on the y-axis and `armspan` on the x-axis.**
    - <span class="blue">Use `add_line()` or `get_line()` to graph a line that you think fits the data well.</span>
- **(2) Fill in the blanks below to create a function that will make predictions of people's `height`s based on their `armspan`:**
```{r, eval = FALSE, echo = TRUE}
predict_height <- function(armspan) {
  ____ * armspan + ____
}
```


## Make your predictions

- **(3) Fill in the blanks to include your predictions in the `arm_span` data.**
```{r, eval = FALSE, echo = TRUE}
____ <- mutate(____, predicted_height = ____(____))
```
- Now that we've made our predictions, we'll need to figure out a way to decide how accurate our predictions are.
    - We'll want to compare our _predicted heights_ to the _actual heights_.
    - At the end, we'll want to come up with a single number summary that describes our model's accuracy.


## Sums of differences

- A _residual_ is the difference between the actual and predicted value of a quantity of interest.
- **(4) Fill in the blanks below to add a column of residuals to `arm_span`.**


```{r, eval = FALSE, echo = TRUE}
____ <- mutate(____, residual = ____ - ____)
```

- **(5) What do the residuals measure?**
- One method we might consider to measure our model's accuracy is to sum the residuals.
- **(6) Fill in the blanks below to calculate our accuracy summary.**


```{r, eval = FALSE, echo = TRUE}
summarize(____, sum(____))
```

- Hint: Like `mutate`, the first argument of `summarize` is a dataframe, and the second argument is the action to perform on a column of the dataframe. Whereas the output of `mutate` is a column, the output of `summarize` is (usually) a single number summary.
- **(7) Describe and interpret, in words, what the output of your accuracy summary means.**
- **(8) Write down why adding positive and negative errors together is problematic for assessing prediction accuracy.**


## Mean squared error

- When adding residuals, the positive errors in our predictions (underestimates) are cancelled out by negative errors (overestimates) which lead to the impression that our model is making better predictions than it actually is.
- To solve this problem we calculate the squared values of the errors because squared values are always positive.
- The _mean squared error_ (MSE) is calculated by squaring all of the residuals, and then taking the mean of the squared residuals.
- **(9) Fill in the blanks below to calculate the MSE of your line.**


```{r, eval = FALSE, echo = TRUE}
summarize(____, mean((____)^2))
```

- **(10) Compare your MSE with a neighbor. Whose line was more accurate and why?**


## Regression lines

- If you were to go around your class, each student would have created a different line that they feel _fit_ the data best.
    - Which is a problem because everyone's line will make slightly different predictions.
- To avoid this variation in predictions, data scientists will use _regression lines_.
    - We also refer to _regression lines_ as _linear models_.
    - This line connects the mean `height` of people with similar `armspan`s.
    - **(11) Fill in the blanks below to create a _regression line_ using `lm`, which stands for _linear model_:**

```{r, eval = FALSE, echo = TRUE}
best_fit <- lm(____ ~ ____, data = arm_span)
```

## Plotting regression lines

- <span class="blue">Type `best_fit` into the console to see the slope and intercept of the regression line.</span>
- **(12) Run the code to create the scatterplot of `armspan` vs. `height` again. Then fill in the blanks below to add the line of best fit.**


```{r, eval = FALSE, echo = TRUE}
add_line(intercept = ____, slope = ____)
```


## Predicting with regression lines

- Making predictions with models `R` is familiar with is simpler than with lines, or models, we come up with ourselves.
    - **(13) Fill in the blanks to make predictions using `best_fit`:**
    
```{r, eval = FALSE, echo = TRUE}
____ <- mutate(____, predicted_height = predict(____))
```

- Hint: the `predict` function takes a linear model as input, and outputs the predictions of that model.


## The magic of lm()

- The `lm()` function creates the _line of best fit_ equation by finding the line that minimizes the _mean squared error_. Meaning, it's the _best fitting line possible_. 
- **(14) Calculate the MSE for the values predicted using the regression line.**
- **(15) Compare the MSE of the linear model you fitted to the MSE of the linear model obtained with `lm()`. Which linear model performed better?**
- **(16) Ask your neighbors if any of their lines beat the `lm()` line in terms of the MSE. Were any of them successful?**

