---
title: "Growing trees"
author: "Lab 4G"
date: 'Directions: Follow along with the slides, completing the questions in <font color=#25679E><b>blue</b></font> on your computer, and answering the questions in **red** in your journal.  
  
  <br>
  <br>
  Space, Click, Right Arrow or swipe left to move to the next slide.'
output: 
  slidy_presentation: 
    css: ../../IDSLabCSSRev.css
    mathjax: ../../extras/mathjax-local/MathJax.js
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, eval=TRUE, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
library(mobilizr)
```

## Trees vs. Lines

- So far in the labs, we've learned how we can fit linear models to our data and use them to make predictions.
- In this lab, we'll learn how to make predictions by growing trees.
    - Instead of creating a line, we split our data into branches based on a series of _yes_ or _no_ questions.
    - The branches help sort our data into _leaves_ which can then be used to make predictions.
- <span class="blue">Start by loading the `titanic` data.</span>


## Our first tree

- **(1) Write and run code using the `tree()` function to create a _classification_ tree that predicts whether a person `survived` the Titanic based on their `sex`.**
    - A _classification_ tree tries to predict which category a categorical variable would belong to based on other variables.
    - The syntax for `tree` is similar to that of the `lm()` function.
    - <span class="blue">Assign this model the name `tree1`.</span>

- **(2) Why can't we just use a _linear model_ to predict whether a passenger on the Titanic `survived` or not based on their `sex`?**


## Viewing trees

- **(3) To actually look at and interpret our `tree1`, write and run code placing the model into the `treeplot` function.**
    - **(4) Write down the labels of the two _branches_.**
    - **(5) Write down the labels of the two _leaves_.**
- Answer the following, based on the `treeplot`:
    - **(6) Which `sex` does the model predict will survive?**
    - **(7) Where does the plot tell you the number of people that get sorted into each leaf? How do you know?**
    - **(8) Where does the plot tell you the number of people that have been sorted _incorrectly_ in each leaf?**


## Leafier trees

- **(9) Similar to how you included multiple variables for a linear model, write and run code creating a `tree` that predicts whether a person `survived` based on their `sex`, `age`, `class`, and where they `embarked`.**
    - <span class="blue">Assign this model the name `tree2`.</span>
- **(10) Write and run code creating a `treeplot` for this model and answer the following questions:**
    - **(11) Mrs. Baxter was a 50-year-old female with a 1st class ticket from Cherbourg. Does the model predict that she survived?**
    - **(12) Which variable ended up not being used by `tree2`?**


## Tree complexity

- By default, the `tree()` function will fit a _tree model_ that will make good predictions without needing lots of branches.
- We can increase the complexity of our trees by changing the complexity parameter, `cp`, which equals `0.01` by default.
- We can also change the minimum number of observations needed in a leaf before we split it into a new branch using `minsplit`, which equals `20` by default.
- **(13) Using the same variables that you used in `tree2`, write and run code creating a model named `tree3` but include `cp = 0.005` and `minsplit = 10` as arguments.**
    - **(14) How is `tree3` different from `tree2`?**

## Predictions and Cross-validation

- Just like with _linear models_, we can use cross-validation to measure how well our _classification trees_ perform on unseen data.
- First, we need to compute the predictions that our model makes on test data.
    - <span class="blue">Use the `data` function to load the `titanic_test` data.</span>
    - **(15) Fill in the blanks below to predict whether people in the `titanic_test` data survived or not using `tree1`.**
    - Note: the argument `type = "class"` tells the `predict` function that we are predicting a categorical variable and not a numerical variable.

```{r, eval = FALSE, echo = TRUE}
titanic_test <- mutate(____, prediction = predict(____, newdata = ____, type = "class"))
```


## Measuring model performance

- Similar to how we use the _mean squared error_ to describe how well our model predicts numerical variables, we use the _misclassification rate_ to describe how our model predicts categorical variables.
    - The _misclassification rate_ (MCR) is the number of people who were predicted to be in one category but were actually in another.
    
- <span class="blue">Run the following command to see a side-by-side comparison of the actual outcome and the predicted outcome:</span>

```{r, eval=FALSE, echo=TRUE}
View(select(titanic_test, survived, prediction))
```

- **(16) Where does the first misclassification occur?**

## Misclassification rate

- In order to tally up the total number of misclassifications, we need to create a function that compares the actual outcome with the predicted outcome. The <b>not equal to</b> operator `!=` will be useful here.
- **(17) Fill in the blanks to create a function to calculate the MCR.**
    - Hint: `sum(____!=____)` will count the number of times that the left-hand side does not equal the right-hand side.
    - We want to count the number of times that actual does not equal predicted and then divide by the total number of observations.


```{r, eval = FALSE, echo = TRUE}
calc_mcr <- function(actual, predicted) {
  sum(____ != ____) / length(actual)
}
```

- <span class="blue">Then run the following to calculate the MCR.</span>


```{r, eval = FALSE, echo = TRUE}
summarize(titanic_test, mcr = calc_mcr(survived, prediction))
```


## On your own

- **(18) In your own words, explain what the _misclassification rate_ is.**
- **(19) Which model (`tree1`, `tree2`, or `tree3`) had the lowest misclassification rate for the `titanic_test` data?**
- **(20) Write and run code creating a 4th model using the same variables used in `tree2`. This time though, change the _complexity parameter_ to `0.0001`. Then answer the following:**
    - **(21) Does creating a more complex _classification tree_ always lead to better predictions? Why not?**
- A _regression tree_ is a tree model that predicts a numerical variable.
- **(22) Write and run code creating a _regression tree_ model to predict the Titanic's passengers' ages and calculate the MSE.**
    - Plots of regression trees are often too complex to plot.